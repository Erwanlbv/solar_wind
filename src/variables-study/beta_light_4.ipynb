{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/erwan/Programmes/2022 Datacamp/solar_wind\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meilleurs modèles basés sur un traitement léger de Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from problem import get_train_data, get_test_data\n",
    "from problem import turn_prediction_to_event_list\n",
    "\n",
    "# Fonction perso\n",
    "from display import plot_event, multiple_plots, display_timeline, show_densities\n",
    "from display import display_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fe_data(data):\n",
    "    \"\"\"\n",
    "    Prend data_train['Beta'] au format brut (hors seuillabge ) et renvoie la série avec les traitements\n",
    "    définis ci-dessous\n",
    "    \"\"\"\n",
    "\n",
    "    # Moyenne mobile faible sur les valeurs pour espérer réduire dors et déjà le bruit \n",
    "    seuil = 50\n",
    "    var_s = data.map(lambda x: min(x, seuil))\n",
    "    var_s = var_s.rolling('30 min', center=True).mean()\n",
    "\n",
    "    # Différence entre moyenne longue et moyenne courte (mobiles) \n",
    "    # Met en avant les transitions entre états\n",
    "    var_l_2h_s = var_s.rolling('2h').mean()\n",
    "    var_r_2h_s = var_s.iloc[::-1].rolling('2h').mean().iloc[::-1]\n",
    "\n",
    "    # Ratio entre une moyenne mobile courte et une très longue\n",
    "    # Met en avant les valeurs faibles de Beta\n",
    "    var_4h_s = var_s.rolling('4h', center=True).mean()\n",
    "    var_long_s = var_s.rolling('4 d', center=True).mean()\n",
    "\n",
    "    var_l_20h_s = var_s.rolling('20h').mean()\n",
    "    var_r_20h_s = var_s.iloc[::-1].rolling('20h').mean().iloc[::-1]\n",
    "\n",
    "    df = pd.DataFrame({})\n",
    "    df['base-value'] = var_s\n",
    "\n",
    "    df['l_small_avg'] = var_l_2h_s.copy()\n",
    "    df['r_small_avg'] = var_r_2h_s.copy()\n",
    "    df['diff-mean'] = (df['r_small_avg'] - df['l_small_avg']).abs()\n",
    "\n",
    "    df['mean-ratio'] = var_4h_s / var_long_s\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données\n",
    "data_train, labels_train = get_train_data()\n",
    "data_test, labels_test = get_test_data()\n",
    "\n",
    "# Évenements\n",
    "events = turn_prediction_to_event_list(labels_train) \n",
    "no_events = turn_prediction_to_event_list(labels_train == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_train_data = get_fe_data(data_train['Beta'])\n",
    "fe_test_data = get_fe_data(data_test['Beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ré-échantillone pour augmenter la proportion de 1\n",
    "# (Pour cela on dégage directement des mesures correpondant à du calme\n",
    "# Aucun traitement pour vérifier la cohérence des données après coup (en gros y'a des trous dans les données)\n",
    "# -> Partie à réaliser pour le programme \"Nettoyage des données\" \n",
    "drop_fe_train = fe_train_data[labels_train == 0].sample(frac=0.55, random_state=1)\n",
    "\n",
    "reduce_fe_data_train = fe_train_data.drop(drop_fe_train.index)\n",
    "reduce_fe_labels_train = labels_train[reduce_fe_data_train.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base-value</th>\n",
       "      <th>l_small_avg</th>\n",
       "      <th>r_small_avg</th>\n",
       "      <th>diff-mean</th>\n",
       "      <th>mean-ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1997-10-01 00:00:00</th>\n",
       "      <td>8.395598</td>\n",
       "      <td>8.395598</td>\n",
       "      <td>9.201718</td>\n",
       "      <td>0.806121</td>\n",
       "      <td>14.461996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-10-01 00:20:00</th>\n",
       "      <td>12.369014</td>\n",
       "      <td>10.112137</td>\n",
       "      <td>7.784553</td>\n",
       "      <td>2.327584</td>\n",
       "      <td>12.637000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     base-value  l_small_avg  r_small_avg  diff-mean  \\\n",
       "1997-10-01 00:00:00    8.395598     8.395598     9.201718   0.806121   \n",
       "1997-10-01 00:20:00   12.369014    10.112137     7.784553   2.327584   \n",
       "\n",
       "                     mean-ratio  \n",
       "1997-10-01 00:00:00   14.461996  \n",
       "1997-10-01 00:20:00   12.637000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_fe_data_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes :  ['base-value', 'mean-ratio', 'diff-mean', 'l_small_avg', 'r_small_avg']\n",
      "\n",
      " Régression Logistique\n",
      "Coefs : [[ 1.24700003  0.26181994  5.53590306 -5.90231127 -5.8820308 ]]\n",
      "Loss : 0.14837895513889757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98    191755\n",
      "           1       0.72      0.50      0.59     13819\n",
      "\n",
      "    accuracy                           0.95    205574\n",
      "   macro avg       0.84      0.74      0.78    205574\n",
      "weighted avg       0.95      0.95      0.95    205574\n",
      "\n",
      "ev_prec 0.5593220338983051\n",
      "ev_rec 0.31775700934579443\n",
      "-------------\n",
      "\n",
      " HistBoost\n",
      "Loss : 0.13568117006308783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98    191755\n",
      "           1       0.72      0.50      0.59     13819\n",
      "\n",
      "    accuracy                           0.95    205574\n",
      "   macro avg       0.84      0.74      0.78    205574\n",
      "weighted avg       0.95      0.95      0.95    205574\n",
      "\n",
      "ev_prec 0.5964912280701755\n",
      "ev_rec 0.3271028037383178\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "cols = ['base-value', 'mean-ratio', 'diff-mean', 'l_small_avg', 'r_small_avg']\n",
    "\n",
    "log_model = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    max_iter=1000,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "histboost_model = HistGradientBoostingClassifier(\n",
    "    max_iter=1000,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "print(\"Colonnes : \", cols)\n",
    "print('\\n Régression Logistique')\n",
    "log_model.fit(reduce_fe_data_train[cols], reduce_fe_labels_train)\n",
    "print('Coefs :', log_model.coef_)\n",
    "display_res(fe_test_data[cols], labels_test, smooth=False, models=[log_model])\n",
    "\n",
    "\n",
    "print(\"\\n HistBoost\")\n",
    "histboost_model.fit(reduce_fe_data_train[cols], reduce_fe_labels_train)\n",
    "display_res(fe_test_data[cols], labels_test, smooth=False, models=[histboost_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 08:29:02) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c43a034baed6525e7d4b54734a34a446a6181c1bda94e67cd174d3b725a42644"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
